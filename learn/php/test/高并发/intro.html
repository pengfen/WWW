高并发和大流量解决方案

PHP如何解决网站大流量与高并发的问题(真题)

并发 在操作系统中 是指一个时间段中有几个程序都处于已启动运行到运行完毕之间 且这个程序都是在同一个处理机上运行 但任一个时刻点上只有一个程序在处理机上运行

上面的定义明显不是我们通常所言的并发 在互联网时代 所讲的并发 高并发 通常是指并发访问 也就是在某个时间点 有多少个访问同时到来

通常如果一个系统的日PV在千万以上 有可能是一个高并发的系统
有的公司完全不走技术路线 全靠机器堆 这不在我们的讨论范围

高并发的问题 我们具体该关心什么
QPS 每秒钟请示或者查询的数量 在互联网领域 指每秒响应请求数(指HTTP请求)
吞吐量 单位时间内处理的请求数量(通常由QPS与并发数决定)
响应时间 从请求发出一收到响应花费的时间 例如系统处理一个HTTP请求需要100ms 这个100ms就是系统的响应时间
PV 综合浏览量(Page View) 即页面浏览量或者点击量 一个访客在24小时内访问的页面数量
同一个人浏览你的网站同一页面 只记作一次PV
UV 独立访客(UniQue Visitor) 即一定时间范围内相同访客多次访问网站 只计算为1个独立访客
带宽 计算带宽大小需关注两个指标 峰值流量和页面的平均大小
日网站带宽 = PV / 统计时间 (换算到秒) * 平均页面大小 (单位KB) * 8
峰值一般是平均值的倍数 根据实现情况来定
QPS 不等于 并发连接数
QPS 是每秒HTTP请求数量 并发连接数是系统同时处理的请求数量
(总PV数 * 80%) / (6小时秒数 * 20%) = 峰值每秒请求数(QPS)
80%的访问量集中在 20%的时间

压力测试
测试能承受的最大并发
测试最大承受的QPS值

ab 全称是apache benchmark 是apache官方推出的工具 创建多个并发访问线程
模拟多个访问都出时对某一URL地址进行访问 它的测试目标是基于URL的 因此 
它既然可以用来测试apache的负载压力 也可以测试nginx lighthttp tomcat iis等其它web服务器的压力

模拟并发请求100次 总共请求5000次
ab -c 100 -n 5000 待测试网站

单独安装ab命令
yum -y install apr-util(ab安装的依赖包)
yum -y install yum-utils
cd /opt
mkdir ab
cd ab
yum install yum-utils.noarch
yumdownloader httpd-tools*
rpm2cpio httpd-*.rpm | cpio -idmv
./usr/bin/ab

测试机器与被测试机器分开
不要对线上服务做压力测试
观察测试工具ab所在机器 以及被测试的前端机的CPU 内存 网络等都不超过最高限度的75%

QPS达到极限
随着QPS的增长 每个阶段需要根据实际情况来进行优化 优化的方案也与硬件条件 网络带宽息息相关
QPS达到50 可以称之为小型网站 一般的服务器就可以应付
QPS达到100 假设关系型数据库的每次请求在0.01秒完成
假设单页面只有一个SQL查询 那么100QPS意味着1秒钟完成100次请求 但是此时我们并不能保证数据库查询能完成100次
方案 数据库缓存层 数据库的负载均衡
QPS达到800 假设我们使用百兆带宽 意味着网站出口的实现带宽是8M左右
假设每个页面只有10K 在这个并发条件下 百兆带宽已经吃完
方案 CDN加速 负载均衡
QPS达到1000 假设使用Memcache缓存数据库查询数据 每个页面对Memcache的请求远大于直接对DB的请求
memcache的悲观并发数在2w左右 但有可能在之前内网带宽已经吃光 表现出不稳定
方案 表态html缓存
QPS达到2000 这个级别下 文件系统访问锁都成为了灾难
方案 做业务分离 分布式存储

流量优化 防盗链
前端优化 减少HTTP请求 添加异步请求 启用浏览器缓存和文件压缩 CDN加速 建立独立图片服务器
服务端优化 页面静态化 并发处理
数据库优化 数据库缓存 分库分表 分区操作 读写分离 负载均衡
web服务器优化 负载均衡





nginx配置缓存策略
本地缓存配置
add_header指令 添加状态码为2XX和3XX的响应头信息
add_header name value [always];
可以设置Pragma/Expires/Cache-Control 可以继承

expires指令 通知浏览器过期时长
expires time; 为负值时表示Cache-Control: no-cache; 当为正或者0时 就表示Cache-Control:max-age=指定的时间
当为max时 会把Expires设置为 ... 相当Cache-Control设置到10年

前端代码和资源的压缩
优势 让资源文件更小 加快文件在网络中的传输 让网页更快的展现 降低带宽和流量开销
压缩方式 JS CSS 图片 HTML代码的压缩
Gzip压缩
JavaScript代码压缩
JavaScript压缩的原理一般是去掉多余的空格和回车 替换长变量名 简化一些代码写法等
JavaScript代码压缩工具很多 有在线工具 有应用程序 有编辑器插件
常用压缩工具 UglifyJS  YUI Compressor Closure Compiler
UglifyJS 压缩 语法检查 美化代码 代码缩减 转化
YUI Compressor 来自Yahoo 只有压缩功能
Closure Compiler 来自Google 功能和UglifyJS 类似 压缩的方式不一样

CSS 代码压缩
原理跟JavaScript压缩原理类似 同样是去除空白符 注释并且优化一些CSS语义规则等
常用压缩工具 YUI Compressor  CSS Compressor
CSS Compressor 压缩时可以选择模式

HTML代码压缩
不建议使用代码压缩 有时会破坏代码结构 可以使用Gzip压缩 当然也可以使用htmlcompressor工具 不过转换后一定要检查代码结构

图片压缩
除了代码的压缩外 有时对图片的压缩也是很有必要 一般情况下图片在Web系统的比重都比较大
压缩工具 tinypng JpegMini ImageOptim

Gzip压缩
Nginx配置
gzip on|off; #是否开启gzip
gzip_buffers 32 4K|16 8K #缓冲(在内存中缓决几块 每块多大)
gzip_comp_level[1-9] #推荐6 压缩级别(级别越高 压的越小 越浪费CPU计算资源)
gzip_disable #正则匹配UA 什么样的uri不进行gzip
gzip_min_length 200 #开始压缩的最小长度
gzip_http_version 1.0|1.1 #开始压缩的http协议版本
gzip_proxied #设置请求者代理服务器 该如何缓存内容
gzip_types text/plain application/xml #对哪些类型的文件用压缩 如txt xml html css
gzip_vary on|off #是否传输gzip压缩标志

CDN加速
什么是CDN
使用CDN的优势
CDN的工作原理
CDN的适用场景

CDN的全称是Content Delivery Network 即内容分发网络
尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节 使内容传输的更快 更稳定
在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络
CDN系统能够实时地根据网络流量和各节点的连接 负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上
本地Cache加速 提高了企业站点(尤其含有大量图片和表态页面站点)的访问速度
跨运营商的网络加速 保证不同网络的用户都得到良好的访问质量
远程访问用户根据DNS负载均衡技术智能自动选择Cache服务器

使用CDN的优势
自动生成服务器的远程Mirror(镜像) cache服务器 远程用户访问时从cache服务器上读取数据 减少远程访问的带宽 分担网络流量 减轻原站点WEB服务器负载等功能
广泛分布的CDN节点加上节点之间的智能冗余机制 可以有效地预防黑客入侵

传统访问
用户在浏览器输入域名发起请求 ---> 解析域名获取服务器IP地址 ---> 根据IP地址找到对应的服务器 ---> 服务器响应并返回数据

使用CDN访问
用户发起请求 ---> 智能DNS的解析(根据IP判断地理位置 接入网类型 选择路由最短和负载最轻的服务器) ---> 取得缓存服务器IP 
---> 把内容返回给用户(如果缓存中有) ---> 向源站发起请求 ---> 将结果返回给用户 ---> 将结果存入缓存服务器

场景
站点或者应用中大量静态资源的加速分发 例如 CSS JS 图片和HTML
大文件下载
直播网站

使用squid反向代理 或者nginx等的反向代理

独立图片服务器的部署
独立的必要性
采用独立域名
独立后的问题

分担Web服务器的I/O负载 将耗费资源的图片服务分离出来 提高服务器的性能和稳定性
能够专门对图片服务器进行优化 为图片服务设置有针对性的缓存方案 减少带宽成本 提高访问速度
提高网站的可扩展性 通过增加图片服务器 提高图片吞吐能力

同一域名下浏览器的并发连接数有限制 突破浏览器连接数的限制
由于cookie的原因 对缓存不利 大部分Web cache都只缓存不带cookie的请求 导致每次的图片请求都不能命中cache

如何进行图片上传和图片同步
NFS共享方式
利用FTP同步

动态语言静态化
什么是动态语言静态化 将现在PHP等动态语言的逻辑代码生成为静态HTML文件 用户访问动态脚本重定向到静态HTML文件的过程
为什么要静态化 动态脚本通常会做逻辑计算和数据查询 访问量越大 服务器压力越大
访问量大时可能会造成CPU负载过高 数据库服务器压力过大
静态化可以减低逻辑处理压力 降低数据库服务器查询压力
静态化的实现方式

使用模板引擎
可以使用Smarty的缓存机制生成静态HTML缓存文件
$smarty->cache_dir = $ROOT."/cache"; //缓存目录
$smarty->caching = true; //是否开启缓存
$smarty->cache_lifetime = "3600"; //缓存时间
$smarty->display(string template[, string cache_id[, string compile_id]]);
$smarty->clear_all_cache(); //清除所有缓存
$smarty->clear_cache('file.html'); //清除指定的缓存
$smarty->clear_cache('article.html', $art_id); // 清除同一个模板下的指定缓存号的缓存

利用ob系列的函数
ob_start() 打开输出控制缓冲
ob_get_contents() 返回输出缓冲区内容
ob_clean() 清空输出缓冲区
ob_end_flush() 冲刷出(送出)输出缓冲区内容并关闭缓冲

代码
ob_start();
//输出到页面的HTML代码
ob_get_contents();
ob_end_flush();
fopen();写入

可以判断文件的inode修改时间 判断是否过期 使用filectime函数

代码
$cache_name = md5(__FILE__). '.html';
$cache_lifetime = 3600;

if (filectime(__FILE__) <= filectime($cache_name) && file_exists($cache_name) && filectime($cache_name) + $cache_lifetime > time()) {
    include $cache_name;
	exit;
}
ob_start();

<b>This is My Script</b>

$content = ob_get_contents();
ob_end_flush();
$handle = fopen($cache_name, 'w');
fwrite($handle, $content);
fclose($handle);

动态语言的并发处理
什么是进程 线程 协程
什么是多进程 多线程
同步阻塞模型
异步非阻塞模型

进程(Process)是计算机中的程序关于某数据集合上的一次运行活动 是系统进行资源分配和调度的基本单位 是操作系统结构的基础
进程的三态模型 多道程序系统中 进程在处理器上交替运行 状态不断地发生变化
运行 当一个进程在处理机上运行时 则称该进程处于运行状态 处于此状态的进程的数目小于等于处理器的数目 对于单处理机系统
处于运行状态的进程只有一个 在没有其他进程可以执行时(如所有进程都在阻塞状态) 通常会自动执行系统的空闲进程

当一个进程获得了除处理机以外的一切所需资源　一旦得到处理机即可运行
则称此进程处于就绪状态 就绪进程可以按多个优先级来划分队列 例如 当一
个进程由于时间片用完而进入就绪状态时 排入低优先级队列 当进程由I/O操作
完成而进入就绪状态时 排入高优先级队列

也称为等待或睡眠状态 一个进程正在等待 某一事件发生(例如请求I/O而等待I/O完成等)
而暂时停止运行; 故称该进程处理阻塞状态

进程的五态模型 对于一个实际的系统 进程的状态及其转换更为复杂
进程已结束运行 回收除进程控制块之外的其他资源 并让其他进程从进程控制块中收集有关信息
是指进程被对换到辅存时的就绪状态 最不能被直接调度的状态 只有当主存中没有活跃就绪态进程
或者是挂起就绪态进程具有更高的优先级 系统将把挂起就绪态进程调回主存并转换为活跃就绪
是指进程已在主存 一旦等待的事件产生便进入活跃就绪状态　
由于用户的并发请求 为每一个请求都创建一个进程显然是行不通的 从系统资源开销方面或是响应用户
请求的效率方面来看 因此操作系统中线程的概念便被引进了
线程 有时被称为轻量级进程(Lightweight Process, LWP) 是程序执行流的最小单元
线程是进程中的一个实体 是被系统独立调度和分派的基本单位 线程自己不拥有系统资源
只拥有一点儿在运行中必不可少的资源 但这可与同属一个进程的其它线程共享进程所拥有的全部资源
一个线程可以创建和撤消另一个线程 同一进程中的多个线程之间可以并发执行
线程是程序中一个单一的顺序控制流程 进程内一个相对独立的 可调度的执行单元
是系统独立调度和分派CPU的基本单位指运行中的程序的调度单位
在单个程序中同时运行多个线程完成不同的工作 称为多线程
每一个程序都至少有一个线程 若程序只有一个线程 那就是程序本身
线程具备运行的所有条件 逻辑上可以运行 在等待处理机
线程占有处理机正运行
线程在等待一个事件(如某个信号量) 逻辑上不可执行
协程是一种用户态的轻量级线程 协程的调度完全由用户控制 协程拥有自己的寄存器上下文和栈
协程调度切换时 将寄存器上下文和栈保存到其他地方 在切回来的时候 恢复先前保存的寄存器上下文和栈
直接操作栈则基本没有内核切换的开销 可以不加锁的访问全局变量 所以上下文的切换非常快
线程是进程内的一个执行单元 进程内至少有一个线程 它们共享进程的地址空间 而进程有自己独立的地址空间
进程是资源分配和拥有的单位 同一个进程内的线程共享进程的资源
二者均可并发执行
每个独立的线程有一个程序运行的入口 顺序执行序列和程序的出口 但是线程不能够独立执行
必须依存在应用程序中 由应用程序提供多个线程执行控制
一个线程可以多个协程 一个进程也可以单独拥有多个协程
线程进程都是同步机制 而协程则是异步
协程能保留上一次调用时的状态 每次过程重入时 就相当于进入上一次调用的状态
同一个时间里 同一个计算机系统中如果允许两个或两个以上的进程处于运行状态 这就是多进程
多开一个进程 多分配一份资源 进程间通讯不方便

多线程
线程就是把一个进程分为很多片 每一片都可以是一个独立的流程与多进程的区别是只会使用一个进程的资源 线程间可以直接通信
单进程单线程 一个人在一个桌子上吃菜
单进程多线程 多个人在同一个桌子上一起吃菜
多进程单线程 多个人每个人在自己的桌子吃菜

多进程
最早的服务器端程序都是通过多进程 多线程来解决并发IO的问题
一个请求创建一个进程 然后子进程进和循环同步堵塞地与客户端连接进行交互 收发处理数据
用多线程模式实现非常简单 线程中可以直接向某一个客户端连接发送数据

步骤
创建一个socket
进入while循环 阻塞在进程accept操作 等待客户端连接进入
主进程在多进程模型下通过fork创建子进程
多线程模型下可以创建子线程
子进程／线程创建成功后进入while循环 阻塞在recv调用上 等待客户端向服务器发送数据
收到数据后服务器程序进行处理然后使用send向客户端发送响应
当客房端连接关闭时 子进程／线程退出并销毁所有资源 主进程／线程会回收掉此子进程／线程

缺点
这种模型严重依赖进程的数量解决并发问题
启动大量进程会带来额外的进程调度消耗

异步非阻塞
现在各种高并发异步IO的服务器程序都是基于epoll实现的
IO复用异步非阻塞程序使用经典的Reactor模型 Reactor顾名思义就是反应堆的意思 它本身不处理任何数据收发 只是可以监视一个socket句柄的事件变化

Reactor模型
Add 添加一个SOCKET到Reactor
Set 修改SOCKET对应的事件 如可读可写
Del 从Reactor中移除
Callback 事件发生后回调指定的函数

Reactor 有四个核心的操作
1.add添加socket监听到reactor
2.set修改事件监听 可以设置监听的类型　如可读 可写
3.del从reactor中移除 不再监听事件
4.callback 事件发生后对应的处理逻辑 一般在add/set时制定

nginx 多线程Reactor
swoole 多线程Reactor + 多进程Worker

PHP的Swoole扩展
消息队列
接口的并发请求

Swoole扩展
PHP的异步 并行 高性能网络通信引擎 使用纯C语言编写 提供了PHP语言的异步多线程服务器 异步TCP/UDP网络客户端 异步MySQL 异步Redis 数据库连接池
AsyncTask 消息队列 毫秒定时器 异步文件读写 异步DNS查询
除了异步IO的支持之外 Swoole为PHP多进程的模式设计了多个并发数据结构和IPC通信机制 可以大大简化多进程并发编程的工作

Swoole2支持了类似Go语言的协程 可以使用完全同步的代码实现异步程序

消息队列
场景说明 用户注册后 需要发注册邮件和注册短信
串行方式 将注册信息写入数据库成功后 发送注册邮件 再发送注册短信
并行方式 将注册信息写入数据库成功后 发送注册邮件的同时 发送注册短信
消息队列方式 将注册信息写入数据库成功后 将成功信息写入队列 此时直接返回成功给用户 写入队列的时间非常短 可以忽略不计 然后异步发送邮件和短信

应用解耦
场景说明 用户下单后 订单系统需要通知库存系统
假如库存系统无法访问 则订单减库存将失败 从而导致订单失败
订单系统与库存系统耦合

引用队列
用户下单后 订单系统完成持久化处理 将消息写入消息队列 返回用户订单下单成功
订阅下单的消息 采用拉／推的方式 获取下单信息 库存系统根据下单信息 进行库存操作

流量削锋
应用场景 秒杀活动 流量瞬时激增 服务器压力大
用户发起请求 服务器接收后 先写入消息队列 假如消息队列长度超过最大值 则直接报错或提示用户
后续程序读取消息队列再做处理

控制请求量 缓解高流量

日志处理
应用场景 解决大量日志的传输
日志采集程序将程序写入消息队列 然后通过日志处理程序的订阅消费日志

消息通讯
应用场景 聊天室
多个客户端订阅同一主题 进行消息发布和接收

常见消息队列产品
Kafka Active

数据库缓存
什么是数据库缓存
为什么要使用缓存
使用MySQL查询缓存
使用Memcache缓存
使用Redis缓存

MySQL 等一些常见的关系型数据库的数据都存储在磁盘当中 在高并发场景下
业务应用对MySQL产生的增 删 改 查的操作造成巨大的 I/O开销和查询压力
这无疑对数据库和服务器都是一种巨大的压力 为了解决些类问题 缓存数据的概念应运而生

极大地解决数据库服务器的压力
提高应用数据的响应速度

常见的缓存形式 内存缓存 文件缓存

缓存数据是为了让客户端很少甚至不访问数据库服务器进行数据的查询
高并发下 能最大程序地降低对数据库服务器的访问压力

用户请求 ---> 数据查询 ---> 连接数据库服务器并查询数据 ---> 将数据缓存起来 (HTML 内存 JSON 序列化数据) ---> 显示给客户端

使用Memcache缓存查询数据
工作原理
Memcache是一个高性能的分布式的内存对象缓存系统　通过在内存里维护一个统一的巨大的hash表
它能够用来存储各种格式的数据 包括图像 视频 文件以及数据库检索的结果等 简单的说就是将数据调用到内存
然后从内丰中读取 从而大大提高读取速度

负载均衡
七层负载均衡的实现
四层负载均衡的实现

七层 基于URL等应用层信息的负载均衡
nginx的proxy是它一个很强大的功能 实现了7层负载均衡
功能强大 性能卓越 运行稳定
配置简单灵活
能够自动剔除工作不正常的后端服务器

nginx负载均衡
内置策略 扩展策略
内置策略 IP Hash  加权轮询
扩展策略 fair策略  通用hash  一致性hash

加权轮询策略
首先将请求都分给高权重的机器 直到该机器的权值降到了比其他机器低 才开始将请求分给下一个高权重的机器
当所有后端机器都down掉时 nginx会立即将所有机器的标志位清成初始状态 以避免造成所有的机器都在timeout的状态

IP Hash策略
nginx内置的另一个负载均衡的策略 流程和轮询很类似　只是其中的算法和具体的策略有些变化
IP Hash算法是一种变相的轮询算法

fair策略
根据后端服务器的响应时间判断负载情况 从中选出负载最轻的机器进行分流

通用Hash 一致性Hash策略
通用hash比较简单 可以以nginx内置的变量为key进行hash 一致性hash采用了nginx内置的一致性hash环 支持memcache

nginx配置
http {
    upstream cluster {
	    server srv1;
		server srv2;
		server srv3;
	}
	server {
	    listen 80;
		location / {
		    proxy_pass http://cluster;
		}
	}
}

四层负载均衡的实现
通过报文中的目标地址和端口 再加上负城均衡设备设置的服务器
选择方式 决定最终选择的内部服务器
LVS实现服务器集群负城均衡有三种方式 NAT DR和TUN